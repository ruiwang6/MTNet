MANCHESTER

--------- HimNet ---------
Seed = 4084
{
    "num_nodes": 277,
    "in_steps": 4,
    "out_steps": 4,
    "time_of_day": true,
    "day_of_week": true,
    "y_time_of_day": true,
    "y_day_of_week": true,
    "lr": 0.001,
    "eps": 0.001,
    "weight_decay": 0.0001,
    "milestones": [
        30,
        50
    ],
    "clip_grad": 5,
    "batch_size": 16,
    "max_epochs": 100,
    "early_stop": 15,
    "model_args": {
        "num_nodes": 277,
        "input_dim": 3,
        "output_dim": 1,
        "tod_embedding_dim": 8,
        "dow_embedding_dim": 8,
        "out_steps": 4,
        "hidden_dim": 64,
        "num_layers": 1,
        "cheb_k": 2,
        "ycov_dim": 2,
        "node_embedding_dim": 16,
        "st_embedding_dim": 16,
        "tf_decay_steps": 4000,
        "use_teacher_forcing": true
    }
}
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
HimNet                                   [16, 4, 277, 1]           4,432
├─Embedding: 1-1                         [16, 8]                   768
├─Embedding: 1-2                         [16, 8]                   56
├─HimEncoder: 1-3                        [16, 4, 277, 64]          --
│    └─ModuleList: 2-1                   --                        --
│    │    └─HimGCRU: 3-1                 [16, 277, 64]             414,720
│    │    └─HimGCRU: 3-2                 [16, 277, 64]             (recursive)
│    │    └─HimGCRU: 3-3                 [16, 277, 64]             (recursive)
│    │    └─HimGCRU: 3-4                 [16, 277, 64]             (recursive)
├─HimEncoder: 1-4                        [16, 4, 277, 64]          --
│    └─ModuleList: 2-2                   --                        --
│    │    └─HimGCRU: 3-5                 [16, 277, 64]             414,720
│    │    └─HimGCRU: 3-6                 [16, 277, 64]             (recursive)
│    │    └─HimGCRU: 3-7                 [16, 277, 64]             (recursive)
│    │    └─HimGCRU: 3-8                 [16, 277, 64]             (recursive)
├─Linear: 1-5                            [16, 277, 16]             1,040
├─HimDecoder: 1-6                        [16, 277, 64]             --
│    └─ModuleList: 2-6                   --                        (recursive)
│    │    └─HimGCRU: 3-9                 [16, 277, 64]             414,720
├─Linear: 1-7                            [16, 277, 1]              65
├─HimDecoder: 1-8                        [16, 277, 64]             (recursive)
│    └─ModuleList: 2-6                   --                        (recursive)
│    │    └─HimGCRU: 3-10                [16, 277, 64]             (recursive)
├─Linear: 1-9                            [16, 277, 1]              (recursive)
├─HimDecoder: 1-10                       [16, 277, 64]             (recursive)
│    └─ModuleList: 2-6                   --                        (recursive)
│    │    └─HimGCRU: 3-11                [16, 277, 64]             (recursive)
├─Linear: 1-11                           [16, 277, 1]              (recursive)
├─HimDecoder: 1-12                       [16, 277, 64]             (recursive)
│    └─ModuleList: 2-6                   --                        (recursive)
│    │    └─HimGCRU: 3-12                [16, 277, 64]             (recursive)
├─Linear: 1-13                           [16, 277, 1]              (recursive)
==========================================================================================
Total params: 1,250,521
Trainable params: 1,250,521
Non-trainable params: 0
Total mult-adds (G): 22.06
==========================================================================================
Input size (MB): 0.35
Forward/backward pass size (MB): 82.40
Params size (MB): 4.98
Estimated Total Size (MB): 87.74
==========================================================================================

Loss: HuberLoss

2025-01-23 15:03:34.542201 Epoch 1  	Train Loss = 3.08230 Val Loss = 3.55707
2025-01-23 15:04:14.644904 Epoch 2  	Train Loss = 2.28289 Val Loss = 3.29026
2025-01-23 15:04:55.218865 Epoch 3  	Train Loss = 2.20415 Val Loss = 3.03299
2025-01-23 15:05:35.849168 Epoch 4  	Train Loss = 2.16022 Val Loss = 2.89835
2025-01-23 15:06:16.621325 Epoch 5  	Train Loss = 2.12518 Val Loss = 2.87194
2025-01-23 15:06:57.537928 Epoch 6  	Train Loss = 2.10106 Val Loss = 2.84299
2025-01-23 15:07:38.593576 Epoch 7  	Train Loss = 2.07732 Val Loss = 2.80807
2025-01-23 15:08:19.859794 Epoch 8  	Train Loss = 2.06133 Val Loss = 2.76056
2025-01-23 15:09:01.015839 Epoch 9  	Train Loss = 2.04469 Val Loss = 2.71174
2025-01-23 15:09:42.238848 Epoch 10  	Train Loss = 2.02945 Val Loss = 2.68336
2025-01-23 15:10:23.480406 Epoch 11  	Train Loss = 2.01771 Val Loss = 2.68331
2025-01-23 15:11:05.203805 Epoch 12  	Train Loss = 2.00597 Val Loss = 2.66573
2025-01-23 15:11:47.210982 Epoch 13  	Train Loss = 1.99125 Val Loss = 2.67513
2025-01-23 15:12:29.081020 Epoch 14  	Train Loss = 1.98203 Val Loss = 2.61635
2025-01-23 15:13:11.035247 Epoch 15  	Train Loss = 1.97255 Val Loss = 2.61568
2025-01-23 15:13:52.618185 Epoch 16  	Train Loss = 1.95983 Val Loss = 2.61095
2025-01-23 15:14:34.449478 Epoch 17  	Train Loss = 1.95561 Val Loss = 2.66059
2025-01-23 15:15:15.938891 Epoch 18  	Train Loss = 1.94323 Val Loss = 2.67059
2025-01-23 15:15:57.389945 Epoch 19  	Train Loss = 1.93273 Val Loss = 2.59043
2025-01-23 15:16:38.976134 Epoch 20  	Train Loss = 1.92532 Val Loss = 2.57407
2025-01-23 15:17:20.423028 Epoch 21  	Train Loss = 1.91814 Val Loss = 2.55740
2025-01-23 15:18:01.893507 Epoch 22  	Train Loss = 1.90959 Val Loss = 2.54380
2025-01-23 15:18:43.420931 Epoch 23  	Train Loss = 1.90564 Val Loss = 2.61523
2025-01-23 15:19:24.682085 Epoch 24  	Train Loss = 1.89883 Val Loss = 2.52498
2025-01-23 15:20:06.510648 Epoch 25  	Train Loss = 1.89406 Val Loss = 2.57253
2025-01-23 15:20:48.270398 Epoch 26  	Train Loss = 1.88668 Val Loss = 2.55045
2025-01-23 15:21:29.847637 Epoch 27  	Train Loss = 1.88247 Val Loss = 2.69607
2025-01-23 15:22:11.474610 Epoch 28  	Train Loss = 1.87569 Val Loss = 2.51020
2025-01-23 15:22:53.242042 Epoch 29  	Train Loss = 1.87246 Val Loss = 2.54165
2025-01-23 15:23:34.705431 Epoch 30  	Train Loss = 1.86929 Val Loss = 2.60993
2025-01-23 15:24:17.080425 Epoch 31  	Train Loss = 1.81917 Val Loss = 2.47436
2025-01-23 15:24:58.873760 Epoch 32  	Train Loss = 1.80922 Val Loss = 2.46903
2025-01-23 15:25:40.764934 Epoch 33  	Train Loss = 1.80889 Val Loss = 2.46215
2025-01-23 15:26:22.504062 Epoch 34  	Train Loss = 1.80336 Val Loss = 2.46784
2025-01-23 15:27:04.580465 Epoch 35  	Train Loss = 1.80630 Val Loss = 2.47498
2025-01-23 15:27:46.078223 Epoch 36  	Train Loss = 1.80453 Val Loss = 2.46441
2025-01-23 15:28:27.221895 Epoch 37  	Train Loss = 1.80401 Val Loss = 2.47119
2025-01-23 15:29:08.447675 Epoch 38  	Train Loss = 1.80521 Val Loss = 2.47209
2025-01-23 15:29:50.321470 Epoch 39  	Train Loss = 1.80338 Val Loss = 2.47085
2025-01-23 15:30:32.299033 Epoch 40  	Train Loss = 1.80317 Val Loss = 2.47423
2025-01-23 15:31:14.310693 Epoch 41  	Train Loss = 1.80614 Val Loss = 2.48360
2025-01-23 15:31:56.275254 Epoch 42  	Train Loss = 1.80815 Val Loss = 2.46487
2025-01-23 15:32:37.749401 Epoch 43  	Train Loss = 1.80836 Val Loss = 2.46638
2025-01-23 15:33:18.843572 Epoch 44  	Train Loss = 1.81270 Val Loss = 2.46794
2025-01-23 15:34:00.000765 Epoch 45  	Train Loss = 1.81262 Val Loss = 2.47168
2025-01-23 15:34:41.228898 Epoch 46  	Train Loss = 1.81885 Val Loss = 2.47003
2025-01-23 15:35:22.435805 Epoch 47  	Train Loss = 1.82976 Val Loss = 2.48190
2025-01-23 15:36:03.659172 Epoch 48  	Train Loss = 1.82741 Val Loss = 2.47434
Early stopping at epoch: 48
Best at epoch 33:
Train Loss = 1.80889
Train RMSE = 6.35925, MAE = 2.63743, MAPE = 4.38176
Val Loss = 2.46215
Val RMSE = 6.73119, MAE = 2.71889, MAPE = 4.39676
--------- Test ---------
All Steps RMSE = 7.11312, MAE = 2.94508, MAPE = 4.93542
Step 1 RMSE = 5.23625, MAE = 2.32535, MAPE = 3.57293
Step 2 RMSE = 6.81342, MAE = 2.84796, MAPE = 4.71498
Step 3 RMSE = 7.70600, MAE = 3.17886, MAPE = 5.45431
Step 4 RMSE = 8.31641, MAE = 3.42819, MAPE = 5.99947
Inference time: 5.28 s
