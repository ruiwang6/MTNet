PEMS04
Trainset:	x-(10181, 12, 307, 3)	y-(10181, 12, 307, 3)
Valset:  	x-(3394, 12, 307, 3)  	y-(3394, 12, 307, 3)
Testset:	x-(3394, 12, 307, 3)	y-(3394, 12, 307, 3)

--------- HimNet ---------
Seed = 2582
{
    "num_nodes": 307,
    "in_steps": 12,
    "out_steps": 12,
    "time_of_day": true,
    "day_of_week": true,
    "y_time_of_day": true,
    "y_day_of_week": true,
    "lr": 0.001,
    "eps": 0.001,
    "weight_decay": 0.0001,
    "milestones": [
        30,
        50
    ],
    "clip_grad": 5,
    "batch_size": 16,
    "max_epochs": 100,
    "early_stop": 15,
    "model_args": {
        "num_nodes": 307,
        "input_dim": 3,
        "output_dim": 1,
        "tod_embedding_dim": 8,
        "dow_embedding_dim": 8,
        "out_steps": 12,
        "hidden_dim": 64,
        "num_layers": 1,
        "cheb_k": 2,
        "ycov_dim": 2,
        "node_embedding_dim": 16,
        "st_embedding_dim": 16,
        "tf_decay_steps": 4000,
        "use_teacher_forcing": true
    }
}
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
HimNet                                   [16, 12, 307, 1]          4,912
├─Embedding: 1-1                         [16, 8]                   2,304
├─Embedding: 1-2                         [16, 8]                   56
├─HimEncoder: 1-3                        [16, 12, 307, 64]         --
│    └─ModuleList: 2-1                   --                        --
│    │    └─HimGCRU: 3-1                 [16, 307, 64]             414,720
│    │    └─HimGCRU: 3-2                 [16, 307, 64]             (recursive)
│    │    └─HimGCRU: 3-3                 [16, 307, 64]             (recursive)
│    │    └─HimGCRU: 3-4                 [16, 307, 64]             (recursive)
│    │    └─HimGCRU: 3-5                 [16, 307, 64]             (recursive)
│    │    └─HimGCRU: 3-6                 [16, 307, 64]             (recursive)
│    │    └─HimGCRU: 3-7                 [16, 307, 64]             (recursive)
│    │    └─HimGCRU: 3-8                 [16, 307, 64]             (recursive)
│    │    └─HimGCRU: 3-9                 [16, 307, 64]             (recursive)
│    │    └─HimGCRU: 3-10                [16, 307, 64]             (recursive)
│    │    └─HimGCRU: 3-11                [16, 307, 64]             (recursive)
│    │    └─HimGCRU: 3-12                [16, 307, 64]             (recursive)
├─HimEncoder: 1-4                        [16, 12, 307, 64]         --
│    └─ModuleList: 2-2                   --                        --
│    │    └─HimGCRU: 3-13                [16, 307, 64]             414,720
│    │    └─HimGCRU: 3-14                [16, 307, 64]             (recursive)
│    │    └─HimGCRU: 3-15                [16, 307, 64]             (recursive)
│    │    └─HimGCRU: 3-16                [16, 307, 64]             (recursive)
│    │    └─HimGCRU: 3-17                [16, 307, 64]             (recursive)
│    │    └─HimGCRU: 3-18                [16, 307, 64]             (recursive)
│    │    └─HimGCRU: 3-19                [16, 307, 64]             (recursive)
│    │    └─HimGCRU: 3-20                [16, 307, 64]             (recursive)
│    │    └─HimGCRU: 3-21                [16, 307, 64]             (recursive)
│    │    └─HimGCRU: 3-22                [16, 307, 64]             (recursive)
│    │    └─HimGCRU: 3-23                [16, 307, 64]             (recursive)
│    │    └─HimGCRU: 3-24                [16, 307, 64]             (recursive)
├─Linear: 1-5                            [16, 307, 16]             1,040
├─HimDecoder: 1-6                        [16, 307, 64]             --
│    └─ModuleList: 2-14                  --                        (recursive)
│    │    └─HimGCRU: 3-25                [16, 307, 64]             414,720
├─Linear: 1-7                            [16, 307, 1]              65
├─HimDecoder: 1-8                        [16, 307, 64]             (recursive)
│    └─ModuleList: 2-14                  --                        (recursive)
│    │    └─HimGCRU: 3-26                [16, 307, 64]             (recursive)
├─Linear: 1-9                            [16, 307, 1]              (recursive)
├─HimDecoder: 1-10                       [16, 307, 64]             (recursive)
│    └─ModuleList: 2-14                  --                        (recursive)
│    │    └─HimGCRU: 3-27                [16, 307, 64]             (recursive)
├─Linear: 1-11                           [16, 307, 1]              (recursive)
├─HimDecoder: 1-12                       [16, 307, 64]             (recursive)
│    └─ModuleList: 2-14                  --                        (recursive)
│    │    └─HimGCRU: 3-28                [16, 307, 64]             (recursive)
├─Linear: 1-13                           [16, 307, 1]              (recursive)
├─HimDecoder: 1-14                       [16, 307, 64]             (recursive)
│    └─ModuleList: 2-14                  --                        (recursive)
│    │    └─HimGCRU: 3-29                [16, 307, 64]             (recursive)
├─Linear: 1-15                           [16, 307, 1]              (recursive)
├─HimDecoder: 1-16                       [16, 307, 64]             (recursive)
│    └─ModuleList: 2-14                  --                        (recursive)
│    │    └─HimGCRU: 3-30                [16, 307, 64]             (recursive)
├─Linear: 1-17                           [16, 307, 1]              (recursive)
├─HimDecoder: 1-18                       [16, 307, 64]             (recursive)
│    └─ModuleList: 2-14                  --                        (recursive)
│    │    └─HimGCRU: 3-31                [16, 307, 64]             (recursive)
├─Linear: 1-19                           [16, 307, 1]              (recursive)
├─HimDecoder: 1-20                       [16, 307, 64]             (recursive)
│    └─ModuleList: 2-14                  --                        (recursive)
│    │    └─HimGCRU: 3-32                [16, 307, 64]             (recursive)
├─Linear: 1-21                           [16, 307, 1]              (recursive)
├─HimDecoder: 1-22                       [16, 307, 64]             (recursive)
│    └─ModuleList: 2-14                  --                        (recursive)
│    │    └─HimGCRU: 3-33                [16, 307, 64]             (recursive)
├─Linear: 1-23                           [16, 307, 1]              (recursive)
├─HimDecoder: 1-24                       [16, 307, 64]             (recursive)
│    └─ModuleList: 2-14                  --                        (recursive)
│    │    └─HimGCRU: 3-34                [16, 307, 64]             (recursive)
├─Linear: 1-25                           [16, 307, 1]              (recursive)
├─HimDecoder: 1-26                       [16, 307, 64]             (recursive)
│    └─ModuleList: 2-14                  --                        (recursive)
│    │    └─HimGCRU: 3-35                [16, 307, 64]             (recursive)
├─Linear: 1-27                           [16, 307, 1]              (recursive)
├─HimDecoder: 1-28                       [16, 307, 64]             (recursive)
│    └─ModuleList: 2-14                  --                        (recursive)
│    │    └─HimGCRU: 3-36                [16, 307, 64]             (recursive)
├─Linear: 1-29                           [16, 307, 1]              (recursive)
==========================================================================================
Total params: 1,252,537
Trainable params: 1,252,537
Non-trainable params: 0
Total mult-adds (G): 73.34
==========================================================================================
Input size (MB): 1.18
Forward/backward pass size (MB): 272.72
Params size (MB): 4.99
Estimated Total Size (MB): 278.89
==========================================================================================

Loss: HuberLoss

2025-01-23 15:52:02.587695 Epoch 1  	Train Loss = 0.79289 Val Loss = 2.25328
2025-01-23 15:54:23.564935 Epoch 2  	Train Loss = 0.57886 Val Loss = 1.74294
2025-01-23 15:56:44.311085 Epoch 3  	Train Loss = 0.56700 Val Loss = 2.46733
2025-01-23 15:59:05.336882 Epoch 4  	Train Loss = 0.56096 Val Loss = 1.70356
2025-01-23 16:01:26.299107 Epoch 5  	Train Loss = 0.55404 Val Loss = 1.63074
2025-01-23 16:03:47.909648 Epoch 6  	Train Loss = 0.55096 Val Loss = 1.65962
2025-01-23 16:06:09.044074 Epoch 7  	Train Loss = 0.54770 Val Loss = 1.67837
2025-01-23 16:08:32.485724 Epoch 8  	Train Loss = 0.54471 Val Loss = 1.62547
2025-01-23 16:10:53.873989 Epoch 9  	Train Loss = 0.54147 Val Loss = 1.67095
2025-01-23 16:13:14.595149 Epoch 10  	Train Loss = 0.53904 Val Loss = 1.64190
2025-01-23 16:15:36.321084 Epoch 11  	Train Loss = 0.53667 Val Loss = 1.52947
2025-01-23 16:17:57.402597 Epoch 12  	Train Loss = 0.53557 Val Loss = 1.54204
2025-01-23 16:20:18.286293 Epoch 13  	Train Loss = 0.53292 Val Loss = 1.59205
2025-01-23 16:22:39.241789 Epoch 14  	Train Loss = 0.53172 Val Loss = 1.62569
2025-01-23 16:25:00.140113 Epoch 15  	Train Loss = 0.53011 Val Loss = 1.47806
2025-01-23 16:27:23.642685 Epoch 16  	Train Loss = 0.52906 Val Loss = 1.45461
2025-01-23 16:29:45.261567 Epoch 17  	Train Loss = 0.52753 Val Loss = 1.46794
2025-01-23 16:32:05.710316 Epoch 18  	Train Loss = 0.52681 Val Loss = 1.45151
2025-01-23 16:34:26.618953 Epoch 19  	Train Loss = 0.52599 Val Loss = 1.43813
2025-01-23 16:36:46.496846 Epoch 20  	Train Loss = 0.52478 Val Loss = 1.46195
2025-01-23 16:39:05.369453 Epoch 21  	Train Loss = 0.52420 Val Loss = 1.55617
2025-01-23 16:41:23.107355 Epoch 22  	Train Loss = 0.52420 Val Loss = 1.44780
2025-01-23 16:43:41.025327 Epoch 23  	Train Loss = 0.52244 Val Loss = 1.43959
2025-01-23 16:45:58.755571 Epoch 24  	Train Loss = 0.52212 Val Loss = 1.46569
2025-01-23 16:48:17.470493 Epoch 25  	Train Loss = 0.52144 Val Loss = 1.40692
2025-01-23 16:50:35.445637 Epoch 26  	Train Loss = 0.52154 Val Loss = 1.42424
2025-01-23 16:52:52.961652 Epoch 27  	Train Loss = 0.52100 Val Loss = 1.38734
2025-01-23 16:55:10.547327 Epoch 28  	Train Loss = 0.52276 Val Loss = 1.44352
2025-01-23 16:57:28.432120 Epoch 29  	Train Loss = 0.52081 Val Loss = 1.52563
2025-01-23 16:59:46.381635 Epoch 30  	Train Loss = 0.52154 Val Loss = 1.46346
2025-01-23 17:02:04.269163 Epoch 31  	Train Loss = 0.51580 Val Loss = 1.37465
2025-01-23 17:04:22.149859 Epoch 32  	Train Loss = 0.51687 Val Loss = 1.37031
2025-01-23 17:06:39.926749 Epoch 33  	Train Loss = 0.51773 Val Loss = 1.37301
2025-01-23 17:08:57.954585 Epoch 34  	Train Loss = 0.52008 Val Loss = 1.36494
2025-01-23 17:11:15.989290 Epoch 35  	Train Loss = 0.52176 Val Loss = 1.36138
2025-01-23 17:13:33.707096 Epoch 36  	Train Loss = 0.52329 Val Loss = 1.35982
2025-01-23 17:15:51.822924 Epoch 37  	Train Loss = 0.52674 Val Loss = 1.35595
2025-01-23 17:18:09.765559 Epoch 38  	Train Loss = 0.53025 Val Loss = 1.36061
2025-01-23 17:20:28.428683 Epoch 39  	Train Loss = 0.53272 Val Loss = 1.35107
2025-01-23 17:22:46.572452 Epoch 40  	Train Loss = 0.53531 Val Loss = 1.35705
2025-01-23 17:25:05.063465 Epoch 41  	Train Loss = 0.53998 Val Loss = 1.36014
2025-01-23 17:27:24.789485 Epoch 42  	Train Loss = 0.54735 Val Loss = 1.35189
2025-01-23 17:29:43.663440 Epoch 43  	Train Loss = 0.54944 Val Loss = 1.35405
2025-01-23 17:32:01.424620 Epoch 44  	Train Loss = 0.55806 Val Loss = 1.33531
2025-01-23 17:34:19.244990 Epoch 45  	Train Loss = 0.56432 Val Loss = 1.33895
2025-01-23 17:36:37.429791 Epoch 46  	Train Loss = 0.57155 Val Loss = 1.34423
2025-01-23 17:38:55.755298 Epoch 47  	Train Loss = 0.58355 Val Loss = 1.33497
2025-01-23 17:41:13.949443 Epoch 48  	Train Loss = 0.59131 Val Loss = 1.34461
2025-01-23 17:43:32.292256 Epoch 49  	Train Loss = 0.60448 Val Loss = 1.34591
2025-01-23 17:45:51.434658 Epoch 50  	Train Loss = 0.61741 Val Loss = 1.32268
2025-01-23 17:48:09.669467 Epoch 51  	Train Loss = 0.63392 Val Loss = 1.31291
2025-01-23 17:50:27.655768 Epoch 52  	Train Loss = 0.64719 Val Loss = 1.31236
2025-01-23 17:52:45.822103 Epoch 53  	Train Loss = 0.66014 Val Loss = 1.31132
2025-01-23 17:55:05.470051 Epoch 54  	Train Loss = 0.67781 Val Loss = 1.30816
2025-01-23 17:57:23.676293 Epoch 55  	Train Loss = 0.70392 Val Loss = 1.31024
2025-01-23 17:59:41.991705 Epoch 56  	Train Loss = 0.72025 Val Loss = 1.30434
2025-01-23 18:01:59.622263 Epoch 57  	Train Loss = 0.74438 Val Loss = 1.30250
2025-01-23 18:04:17.985388 Epoch 58  	Train Loss = 0.76471 Val Loss = 1.30012
2025-01-23 18:06:36.334553 Epoch 59  	Train Loss = 0.78607 Val Loss = 1.29918
2025-01-23 18:08:54.701748 Epoch 60  	Train Loss = 0.81137 Val Loss = 1.29807
2025-01-23 18:11:12.904403 Epoch 61  	Train Loss = 0.82425 Val Loss = 1.29357
2025-01-23 18:13:31.446316 Epoch 62  	Train Loss = 0.85079 Val Loss = 1.29655
2025-01-23 18:15:50.464810 Epoch 63  	Train Loss = 0.87745 Val Loss = 1.29252
2025-01-23 18:18:08.313341 Epoch 64  	Train Loss = 0.89246 Val Loss = 1.29142
2025-01-23 18:20:26.709059 Epoch 65  	Train Loss = 0.90660 Val Loss = 1.28882
2025-01-23 18:22:45.163179 Epoch 66  	Train Loss = 0.92121 Val Loss = 1.28646
2025-01-23 18:25:02.794188 Epoch 67  	Train Loss = 0.94873 Val Loss = 1.28743
2025-01-23 18:27:20.958016 Epoch 68  	Train Loss = 0.94043 Val Loss = 1.28551
2025-01-23 18:29:39.675451 Epoch 69  	Train Loss = 0.96536 Val Loss = 1.28459
2025-01-23 18:31:58.136972 Epoch 70  	Train Loss = 0.97646 Val Loss = 1.28607
2025-01-23 18:34:16.303424 Epoch 71  	Train Loss = 0.99164 Val Loss = 1.28606
2025-01-23 18:36:34.129662 Epoch 72  	Train Loss = 0.98868 Val Loss = 1.28272
2025-01-23 18:38:53.186539 Epoch 73  	Train Loss = 0.99674 Val Loss = 1.28199
2025-01-23 18:41:11.077762 Epoch 74  	Train Loss = 1.00727 Val Loss = 1.28109
2025-01-23 18:43:28.847468 Epoch 75  	Train Loss = 1.00907 Val Loss = 1.28053
2025-01-23 18:45:46.911374 Epoch 76  	Train Loss = 1.01860 Val Loss = 1.28143
2025-01-23 18:48:05.473974 Epoch 77  	Train Loss = 1.01327 Val Loss = 1.27806
2025-01-23 18:50:23.642716 Epoch 78  	Train Loss = 1.01997 Val Loss = 1.27925
2025-01-23 18:52:42.178176 Epoch 79  	Train Loss = 1.02291 Val Loss = 1.27880
2025-01-23 18:55:00.928613 Epoch 80  	Train Loss = 1.02545 Val Loss = 1.27709
2025-01-23 18:57:19.032283 Epoch 81  	Train Loss = 1.02294 Val Loss = 1.27896
2025-01-23 18:59:38.241887 Epoch 82  	Train Loss = 1.02666 Val Loss = 1.27509
2025-01-23 19:01:56.207086 Epoch 83  	Train Loss = 1.02758 Val Loss = 1.27719
2025-01-23 19:04:14.712987 Epoch 84  	Train Loss = 1.02895 Val Loss = 1.27671
2025-01-23 19:06:33.241308 Epoch 85  	Train Loss = 1.02803 Val Loss = 1.27514
2025-01-23 19:08:51.648658 Epoch 86  	Train Loss = 1.02865 Val Loss = 1.27564
2025-01-23 19:11:09.799959 Epoch 87  	Train Loss = 1.03044 Val Loss = 1.27566
2025-01-23 19:13:28.276403 Epoch 88  	Train Loss = 1.02866 Val Loss = 1.27298
2025-01-23 19:15:46.655732 Epoch 89  	Train Loss = 1.03124 Val Loss = 1.27356
2025-01-23 19:18:04.581417 Epoch 90  	Train Loss = 1.02739 Val Loss = 1.27457
2025-01-23 19:20:23.047609 Epoch 91  	Train Loss = 1.02713 Val Loss = 1.27442
2025-01-23 19:22:40.915138 Epoch 92  	Train Loss = 1.02832 Val Loss = 1.27218
2025-01-23 19:24:59.297198 Epoch 93  	Train Loss = 1.02846 Val Loss = 1.27305
2025-01-23 19:27:17.459659 Epoch 94  	Train Loss = 1.02695 Val Loss = 1.27285
2025-01-23 19:29:35.570074 Epoch 95  	Train Loss = 1.02679 Val Loss = 1.27204
2025-01-23 19:31:53.665838 Epoch 96  	Train Loss = 1.02632 Val Loss = 1.27214
2025-01-23 19:34:11.848478 Epoch 97  	Train Loss = 1.02555 Val Loss = 1.27415
2025-01-23 19:36:29.935614 Epoch 98  	Train Loss = 1.02527 Val Loss = 1.27560
2025-01-23 19:38:47.787560 Epoch 99  	Train Loss = 1.02542 Val Loss = 1.27104
2025-01-23 19:41:06.172002 Epoch 100  	Train Loss = 1.02448 Val Loss = 1.27245
Early stopping at epoch: 100
Best at epoch 99:
Train Loss = 1.02542
Train RMSE = 3.11050, MAE = 1.38708, MAPE = 2.84227
Val Loss = 1.27104
Val RMSE = 3.82360, MAE = 1.64450, MAPE = 3.64188
--------- Test ---------
All Steps RMSE = 3.71251, MAE = 1.58263, MAPE = 3.33915
Step 1 RMSE = 1.70719, MAE = 0.89605, MAPE = 1.63808
Step 2 RMSE = 2.35326, MAE = 1.15568, MAPE = 2.20377
Step 3 RMSE = 2.83303, MAE = 1.32491, MAPE = 2.61501
Step 4 RMSE = 3.20941, MAE = 1.45193, MAPE = 2.95548
Step 5 RMSE = 3.52910, MAE = 1.55578, MAPE = 3.24634
Step 6 RMSE = 3.77585, MAE = 1.63792, MAPE = 3.47728
Step 7 RMSE = 3.97279, MAE = 1.70576, MAPE = 3.66557
Step 8 RMSE = 4.13736, MAE = 1.76323, MAPE = 3.82218
Step 9 RMSE = 4.28000, MAE = 1.81422, MAPE = 3.95704
Step 10 RMSE = 4.39770, MAE = 1.85720, MAPE = 4.06782
Step 11 RMSE = 4.50043, MAE = 1.89589, MAPE = 4.16572
Step 12 RMSE = 4.59235, MAE = 1.93301, MAPE = 4.25549
Inference time: 17.42 s
